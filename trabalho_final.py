# -*- coding: utf-8 -*-
"""Trabalho_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nF22R4aAstHLlcEJJJhfhl781vwZPCYf

# Pacotes
"""

import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import numpy as np
from sklearn import feature_extraction, model_selection, naive_bayes, metrics
from imblearn.over_sampling import SMOTE
from sklearn.naive_bayes import MultinomialNB
import sklearn.metrics as sklm
import seaborn as sns
from sklearn.naive_bayes import ComplementNB
import numpy as np
from sklearn.metrics import confusion_matrix
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from imblearn.under_sampling import RandomUnderSampler
from sklearn.model_selection import RandomizedSearchCV 
import numpy as np
from prettytable import PrettyTable
import sklearn
from numpy import arange
from sklearn.svm import SVC
from sklearn.model_selection import cross_validate
from sklearn.metrics import recall_score
from google.colab import drive

"""# Fun√ß√µes de apoio"""

########################
###### listToString ####
########################


def listToString(s): 
    str1 = " " 
    return (str1.join(s))

##############################
###### Matriz de confus√£o ####
##############################

def matriz_confusao(y_real,y_predito,modelo):

  ### Grafico ###

  tabela=confusion_matrix(y_real,y_predito)

  group_names = ["True Neg","False Pos","False Neg","True Pos"]
  group_counts = ["{0:0.0f}".format(value) for value in
                tabela.flatten()]
  group_percentages = ["{0:.5%}".format(value) for value in
                     tabela.flatten()/np.sum(tabela)]
  labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
  labels = np.asarray(labels).reshape(2,2)
  f = plt.figure()
  f.set_figwidth(8)
  f.set_figheight(8)

  sns.heatmap(tabela, annot=labels, fmt="", cmap='Blues')

  ### Tabela ###
  Resultados=PrettyTable()
  Resultados.field_names=["M√©trica","Resultado"]
  Resultados.title= modelo
  Resultados.align["M√©trica"]="l"
  Resultados.align["Resultado"]="r"

  Resultados.add_row(["Acur√°cia:",round(sklearn.metrics.accuracy_score(y_real,y_predito),2)])
  Resultados.add_row(["Precis√£o:",round(sklearn.metrics.precision_score(y_real,y_predito),2)])
  Resultados.add_row(["Recall:",round(sklearn.metrics.recall_score(y_real,y_predito),2)])
  Resultados.add_row(["F1-Score:",round(sklearn.metrics.f1_score(y_real,y_predito),2)])

  print(Resultados)
  
  return

"""# Conjunto de mensagens SMS a serem classificadas como spam ou mensagens leg√≠timas:"""

sms = pd.read_csv('https://raw.githubusercontent.com/D3B0R4H/Trabalho3/master/SMSSpamCollection', sep='\t', header=None)
sms.head()

sms.columns = ['class', 'text']
sms.head()

"""# An√°lise explorat√≥ria do dataset e tratamento"""

sms.info()

sms['class'].value_counts()/len(sms)

sms['class'].value_counts()

"""Temos mais mensagens genu√≠nas do que de spam no dataset, o que pode gerar problemas no momento de treinar o modelo."""

Counter(' '.join(sms['text']).lower().split()).most_common(50)

"""√â poss√≠vel notar que as principais palavras s√£o stop words. Para uma melhor an√°lise, precisamos retir√°-las, pois elas n√£o ser√£o importantes na classifica√ß√£o.

"""

feat_ext = feature_extraction.text.CountVectorizer(stop_words = 'english', encoding='ansi')
feat_ext.get_stop_words()
stop_words = feat_ext.get_stop_words()

sms_1 = ' '.join(sms['text']).lower().split()
sms_limpo = [word for word in sms_1 if word not in stop_words]

Counter(sms_limpo).most_common(10)

"""Temos como as palavras mais frequentes abrevia√ß√µes normalmente utilizadas em mensagens: u - you, 2 - to, ur - you are, 4 - for; Tamb√©m temos I'm que deveria estar nas stopwords e pontua√ß√£o. Algumas pontua√ß√µes permanecem juntas das palavras, outro ponto a ser corrigido.

Palavras que indiquem que a pessoa deva clicar em algo, que demonstre urg√™ncia em resposta ou algo muito f√°cil pode nos ajudar e indicar se √© phishing. J√° palavras imperativas, motivadoras que indiquem promo√ß√µes, ou nome de empresas podem indicar spam.  


Tamb√©m podemos pensar que as mensagens de spam indiquem algum link ou p√°gina, o que poderia ser mais facilmente identificado se separarmos as palavras tamb√©m por pontos.
"""

# Carregando as Stopwords em uma lista
NLTK_stop_words_list=stopwords.words('english')
print(NLTK_stop_words_list)
print("Total numbers of stop words are ")
print(len(NLTK_stop_words_list))

# Inserindo stopwords de um arquivo pessoal
custom_stop_word_list = ' '.join(pd.read_csv('https://raw.githubusercontent.com/D3B0R4H/Trabalho3/master/StopWords.csv', sep=";")['SW']).lower().split()

final_stopword_list = custom_stop_word_list + NLTK_stop_words_list

"""Stopwords atualizadas."""

sms_1 = ' '.join(sms['text']).lower().replace('.', ' ').replace(',', ' ').replace('?', ' ? ').replace('!', ' ! ').replace('\\', ' \\ ').replace(':', ' : ').replace(';', ' ; ').replace('-', ' - ').replace('_', ' _ ').replace('@', ' @ ').replace('(', ' ').replace(')', ' ').replace('$', ' $ ').replace('¬£', ' ¬£ ').split()
sms_limpo = [word for word in sms_1 if word not in final_stopword_list]

Counter(sms_limpo).most_common(10)

count_sms_limpo = pd.DataFrame.from_dict(Counter(sms_limpo).most_common(50))
count_sms_limpo.plot(kind = 'bar', legend = False, figsize = (15, 3.5))
plt.xticks(np.arange(50), count_sms_limpo[0])
plt.title('Termos mais frequentes')
plt.xlabel('Termos')
plt.ylabel('Contagem')
plt.show()

sms['text_trat']=1

for i in range(0,len(sms),1):
    a= sms['text'][i].lower().replace('.', ' ').replace(',', ' ').replace('?', ' ? ').replace('!', ' ! ').replace('\\', ' \\ ').replace(':', ' : ').replace(';', ' ; ').replace('-', ' - ').replace('_', ' _ ').replace('@', ' @ ').replace('(', ' ').replace(')', ' ').replace('$', ' $ ').replace('¬£', ' ¬£ ').split()
    sms['text_trat'][i] = listToString([sla for sla in a if sla not in final_stopword_list])

#sms

drive.mount('/drive', force_remount=True)
sms[['class','text_trat']].to_csv('/drive/My Drive/Colab_Github/Colab_Github/sms.csv',index=False)

sms_trat= sms[['class','text_trat']]
sms_trat.columns = ['class', 'text']

"""Matriz esparsa para economizar mem√≥ria!

Atributo  ùëó  (coluna) na linha  ùëñ  √© igual √† quantidade de vezes que a palavra associada ao √≠ndice  ùëó  aparece na SMS de √≠ndice  ùëñ .

"""

X = feat_ext.fit_transform(sms_trat['text'])
print(np.shape(X))
# Dicotomizar as classes
sms['class'] = sms['class'].map({'spam':1,'ham':0})

"""Ent√£o temos nesta matriz 8431 palavras e 5572 SMSs

Separando os dados em treinamento e teste:

"""

X_train, X_test, y_train, y_test, idx_train, idx_test = model_selection.train_test_split(
    X, sms['class'], sms.index, test_size = 0.33,random_state= 42)

print([np.shape(X_train), np.shape(X_test)])

"""Para balancear os dados de treinamento, utilizaremos undersampling, foi adotada a porcentagem relativa, para que sejam descartados menos dados da classe majorit√°ria.

"""

# sampling_strategy √© o argumento que indica a porcentagem relativa da classe minorit√°ria.

undersample = RandomUnderSampler(random_state=200, sampling_strategy=0.25)
X_train_US, y_train_US = undersample.fit_resample(X_train, y_train)
X_train_US.shape

X_train.shape

y_train.shape

"""# Modelagem Multinomial Naive Bayes


 * Consideramos a independ√™ncia condicional entre os atributos, isto √© a ocorr√™ncia das palavras n√£o se influenciam.
 
 * Multinomial Na√Øve Bayes considera um vetor de caracter√≠stica onde um determinado termo representa o n√∫mero de vezes que aparece, isto √©, a frequ√™ncia.

## Undersampling para treinamento do modelo
"""

Classificador_US = MultinomialNB()


lista_parametros = {'alpha': [ i+0.1 for i in arange(0.0,2.0,0.1)]}

rand_search = RandomizedSearchCV(Classificador_US, 
                                 param_distributions = lista_parametros,
                                 cv = 10,
                                 random_state = 42,
                                 scoring = 'f1') 
rand_search.fit(X_train_US,y_train_US) 
Classificador_US = rand_search.best_estimator_

Classificador_US

"""# Modelagem Complement Naive Bayes

 * Consideramos a independ√™ncia condicional entre os atributos, isto √© a ocorr√™ncia das palavras n√£o se influenciam.
 
 * CNB √© uma adapta√ß√£o do Multinomial Naive Bayes, sendo que √© particularmente adequado para conjuntos de dados desbalanceados.
"""

Classificador2 = ComplementNB().fit(X_train,y_train)


Classificador_ComplementNB = ComplementNB()


lista_parametros = {'alpha': [ i+0.1 for i in arange(0.0,2.0,0.1)]}

rand_search = RandomizedSearchCV(Classificador_ComplementNB, 
                                 param_distributions = lista_parametros,
                                 cv = 10,
                                 random_state = 42,
                                 scoring = 'f1') 
rand_search.fit(X_train,y_train) 

Classificador_ComplementNB = rand_search.best_estimator_

Classificador_ComplementNB

"""# SVM"""

classificador_SVM = SVC(probability = True, random_state = 42)

lista_parametros = {"C": [ i for i in range(0,100,10)],
             "gamma": [0.001, 0.01, 0.1, 1],
             "kernel": ["linear", "poly", "rbf", "sigmoid"]
       }
              
rand_search = RandomizedSearchCV(classificador_SVM, 
                                 param_distributions = lista_parametros,
                                 cv = 10,
                                 random_state = 42,
                                 scoring = 'f1') 
rand_search.fit(X_train,y_train) 

classificador_SVM = rand_search.best_estimator_

classificador_SVM

"""# 10-Fold Cross Validation"""

scoring = ['accuracy','f1','precision', 'recall']
scores_Classificador_US = cross_validate(Classificador_US,X_train_US,y_train_US, scoring=scoring, cv= 10)
scores_Classificador_ComplementNB = cross_validate(Classificador_ComplementNB,X_train,y_train, scoring=scoring, cv=10)
scores_classificador_SVM = cross_validate(classificador_SVM,X_train,y_train, scoring=scoring, cv=10)
#sorted(scores.keys())
#scores
## 10-fold expl√≠cito

scores_Classificador_US

Resultados=PrettyTable()
  Resultados.field_names=["M√©dia da m√©trica","MultinomialNB","ComplementNB","SVM"]
  Resultados.title= 'Tabela 10-Fold'
  Resultados.align["M√©dia da m√©trica"]="l"
  Resultados.align["ComplementNB"]="c"
  Resultados.align["MultinomialNB"]="c"
  Resultados.align["SVM"]="c"

  Resultados.add_row(["Acur√°cia:",scores_Classificador_US['test_accuracy'].mean().round(2),scores_Classificador_ComplementNB['test_accuracy'].mean().round(2),scores_classificador_SVM['test_accuracy'].mean().round(2)])
  Resultados.add_row(["Precis√£o:",scores_Classificador_US['test_precision'].mean().round(2),scores_Classificador_ComplementNB['test_precision'].mean().round(2),scores_classificador_SVM['test_precision'].mean().round(2)])
  Resultados.add_row(["Recall:",scores_Classificador_US['test_recall'].mean().round(2),scores_Classificador_ComplementNB['test_recall'].mean().round(2),scores_classificador_SVM['test_recall'].mean().round(2)])
  Resultados.add_row(["F1-Score:",scores_Classificador_US['test_f1'].mean().round(2),scores_Classificador_ComplementNB['test_f1'].mean().round(2),scores_classificador_SVM['test_f1'].mean().round(2)])

  print(Resultados)

"""# Valida√ß√£o teste"""

matriz_confusao(y_test,Classificador_US.predict(X_test),'MultinomialNB')

matriz_confusao(y_test,Classificador_ComplementNB.predict(X_test),'ComplementNB')

matriz_confusao(y_test,classificador_SVM.predict(X_test),'SVM')